<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Rozdział 2 Rozkład normalny | Statystyka w języku Python</title>
  <meta name="description" content="Zbiór zastosowań języka Python w statystyce." />
  <meta name="generator" content="bookdown 0.10 and GitBook 2.6.7" />

  <meta property="og:title" content="Rozdział 2 Rozkład normalny | Statystyka w języku Python" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Zbiór zastosowań języka Python w statystyce." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Rozdział 2 Rozkład normalny | Statystyka w języku Python" />
  
  <meta name="twitter:description" content="Zbiór zastosowań języka Python w statystyce." />
  

<meta name="author" content="Krzysztof Trajkowski" />


<meta name="date" content="2019-08-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html">
<link rel="next" href="R3.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statystyka w języku Python </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Statystyki rozkładu</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#R11"><i class="fa fa-check"></i><b>1.1</b> Rozkład dyskretny</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#R12"><i class="fa fa-check"></i><b>1.2</b> Rozkład ciągły</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="R2.html"><a href="R2.html"><i class="fa fa-check"></i><b>2</b> Rozkład normalny</a><ul>
<li class="chapter" data-level="2.1" data-path="R2.html"><a href="R2.html#R21"><i class="fa fa-check"></i><b>2.1</b> Funkcja gęstości</a></li>
<li class="chapter" data-level="2.2" data-path="R2.html"><a href="R2.html#R22"><i class="fa fa-check"></i><b>2.2</b> Liniowy model regresji</a></li>
<li class="chapter" data-level="2.3" data-path="R2.html"><a href="R2.html#R23"><i class="fa fa-check"></i><b>2.3</b> Nieliniowy model regresji</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="R3.html"><a href="R3.html"><i class="fa fa-check"></i><b>3</b> Rozkład gamma</a><ul>
<li class="chapter" data-level="3.1" data-path="R3.html"><a href="R3.html#R31"><i class="fa fa-check"></i><b>3.1</b> Funkcja gęstości</a></li>
<li class="chapter" data-level="3.2" data-path="R3.html"><a href="R3.html#R32"><i class="fa fa-check"></i><b>3.2</b> Liniowy model gamma regresji</a></li>
<li class="chapter" data-level="3.3" data-path="R3.html"><a href="R3.html#R33"><i class="fa fa-check"></i><b>3.3</b> Nieliniowy model gamma regresji</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="R4.html"><a href="R4.html"><i class="fa fa-check"></i><b>4</b> Rozkład beta</a><ul>
<li class="chapter" data-level="4.1" data-path="R4.html"><a href="R4.html#R41"><i class="fa fa-check"></i><b>4.1</b> Funkcja gęstości</a></li>
<li class="chapter" data-level="4.2" data-path="R4.html"><a href="R4.html#R42"><i class="fa fa-check"></i><b>4.2</b> Liniowy model beta regresji</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="R5.html"><a href="R5.html"><i class="fa fa-check"></i><b>5</b> Rozkład beta dwumianowy</a><ul>
<li class="chapter" data-level="5.1" data-path="R5.html"><a href="R5.html#R51"><i class="fa fa-check"></i><b>5.1</b> Funkcja gęstości</a></li>
<li class="chapter" data-level="5.2" data-path="R5.html"><a href="R5.html#R52"><i class="fa fa-check"></i><b>5.2</b> Liniowy model beta dwumianowej regresji</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="R6.html"><a href="R6.html"><i class="fa fa-check"></i><b>6</b> Rozkład ujemny dwumianowy</a><ul>
<li class="chapter" data-level="6.1" data-path="R6.html"><a href="R6.html#R61"><i class="fa fa-check"></i><b>6.1</b> Funkcja gęstości</a></li>
<li class="chapter" data-level="6.2" data-path="R6.html"><a href="R6.html#R62"><i class="fa fa-check"></i><b>6.2</b> Liniowy model ujemnej dwumianowej regresji</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="R7.html"><a href="R7.html"><i class="fa fa-check"></i><b>7</b> Błąd standardowy estymatora</a><ul>
<li class="chapter" data-level="7.1" data-path="R7.html"><a href="R7.html#R71"><i class="fa fa-check"></i><b>7.1</b> Średnia</a></li>
<li class="chapter" data-level="7.2" data-path="R7.html"><a href="R7.html#R72"><i class="fa fa-check"></i><b>7.2</b> Proporcja</a></li>
<li class="chapter" data-level="7.3" data-path="R7.html"><a href="R7.html#R73"><i class="fa fa-check"></i><b>7.3</b> Mediana</a></li>
<li class="chapter" data-level="7.4" data-path="R7.html"><a href="R7.html#R74"><i class="fa fa-check"></i><b>7.4</b> Wariancja</a></li>
<li class="chapter" data-level="7.5" data-path="R7.html"><a href="R7.html#R75"><i class="fa fa-check"></i><b>7.5</b> Średnia ucięta</a></li>
<li class="chapter" data-level="7.6" data-path="R7.html"><a href="R7.html#R76"><i class="fa fa-check"></i><b>7.6</b> Skośność</a></li>
<li class="chapter" data-level="7.7" data-path="R7.html"><a href="R7.html#R77"><i class="fa fa-check"></i><b>7.7</b> Kurtoza</a></li>
<li class="chapter" data-level="7.8" data-path="R7.html"><a href="R7.html#R78"><i class="fa fa-check"></i><b>7.8</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="R8.html"><a href="R8.html"><i class="fa fa-check"></i><b>8</b> Porównanie zmiennych niezależnych</a><ul>
<li class="chapter" data-level="8.1" data-path="R8.html"><a href="R8.html#R81"><i class="fa fa-check"></i><b>8.1</b> Porównanie średnich</a></li>
<li class="chapter" data-level="8.2" data-path="R8.html"><a href="R8.html#R82"><i class="fa fa-check"></i><b>8.2</b> Porównanie rang</a></li>
<li class="chapter" data-level="8.3" data-path="R8.html"><a href="R8.html#R83"><i class="fa fa-check"></i><b>8.3</b> Porównanie wariancji</a></li>
<li class="chapter" data-level="8.4" data-path="R8.html"><a href="R8.html#R84"><i class="fa fa-check"></i><b>8.4</b> Porównanie rozkładów</a></li>
<li class="chapter" data-level="8.5" data-path="R8.html"><a href="R8.html#R85"><i class="fa fa-check"></i><b>8.5</b> Moc testu</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="R9.html"><a href="R9.html"><i class="fa fa-check"></i><b>9</b> Porównanie zmiennych zależnych</a><ul>
<li class="chapter" data-level="9.1" data-path="R9.html"><a href="R9.html#R91"><i class="fa fa-check"></i><b>9.1</b> Porównanie średnich</a></li>
<li class="chapter" data-level="9.2" data-path="R9.html"><a href="R9.html#R93"><i class="fa fa-check"></i><b>9.2</b> Porównanie rang</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i>Bibliografia</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statystyka w języku Python</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="R2" class="section level1">
<h1><span class="header-section-number">Rozdział 2</span> Rozkład normalny</h1>
<hr />
<div id="R21" class="section level2">
<h2><span class="header-section-number">2.1</span> Funkcja gęstości</h2>
<p>Do funkcji <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gennorm.html"><code>scipy.stats.gennorm.pdf</code></a> został zaimplementowany uogólniony rozkład normalny <span class="math inline">\(GN(x\;|\;\beta,m,s)\)</span> który można przedstawić za pomocą wzoru:
<span class="math display" id="eq:n01">\[\begin{equation}
f(x\;|\;\beta,m,s)=\frac{\beta}{2\,s\,\Gamma(1/\beta)}\exp\left(-\left|\frac{x-m}{s}\right|^\beta\right)
\tag{2.1}
\end{equation}\]</span>
gdzie <span class="math inline">\(\beta\)</span> to parametr kształtu (shape), <span class="math inline">\(s&gt;0\)</span> to parametr skali (scale) oraz <span class="math inline">\(m\)</span> to parametr przesunięcia. Przypadek dla <span class="math inline">\(\beta=2\)</span> został zaimplementowany do funkcji <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm"><code>scipy.stats.norm.pdf</code></a> czyli klasycznej wersji rozkładu normalnego <span class="math inline">\(N(x\;|\;m,s)\)</span> i jest dana wzorem:
<span class="math display" id="eq:n02">\[\begin{equation}
f(x\;|\;m,s)=\frac{1}{s\sqrt{2\pi}}\exp{\left(-\frac{(x-m)^2}{2s^2}\right)}
\tag{2.2}
\end{equation}\]</span></p>
<p>Do oszacowania parametrów rozkładu normalnego można wykorzystać funkcje <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm"><code>scipy.stats.norm.fit</code></a> która wykorzystuje metodę największej wiarygodności. Inaczej mówiąc, oszacowanie parametrów w rozkładzie normalnym sprowadza się do wyznaczenia estymatora średniej oraz obciążonego estymatora odchylenia standardowego na podstawie wzorów:
<span class="math display">\[\hat{m}=\;E(X)=\;\sum_{i=1}^{n}x_i/n,
\quad\mbox{oraz}\quad \hat{s}_{\textrm{ML}}=\;\sqrt{V(X)}\quad=\sqrt{\sum_{i=1}^{n}(x_i-\hat{\mu})^2/n}
\]</span>
Dodajmy, że dla małych próbek zalecane jest stosowanie nieobciążonego estymatora odchylenia standardowego <span class="math inline">\(\hat{s}=\sqrt{\sum_{i=1}^{n}(x_i-\hat{m})^2/(n-1)}\)</span>
ale wraz ze wzrostem liczebności próby różnice między estymatorem obciążonym <span class="math inline">\(\hat{s}_\textrm{ML}\)</span> a nieobciążonym <span class="math inline">\(\hat{s}\)</span> zanikają. Warto zaznaczyć, że estymator parametru skali w uogólnionym rozkładzie normalnym dla <span class="math inline">\(\beta=2\)</span> będzie równy <span class="math inline">\(\hat{s}\sqrt{2}\)</span>.</p>
<p>Gdy założymy, że parametr średniej (przesunięcie funkcji) <span class="math inline">\(m=0\)</span> i parametr odchylenia standardowego (skalowanie funkcji) <span class="math inline">\(s=1\)</span> to ogólny wzór funkcji <span class="math inline">\(f(x\;|\;m,s)\)</span> uprości się do postaci standardowej:
<span class="math display" id="eq:n03">\[\begin{equation}
f(x)=\frac{1}{\sqrt{2\pi}}\exp{\left(-\frac{x^2}{2}\right)}
\tag{2.3}
\end{equation}\]</span>
Warto zauważyć, że dokonując prostych przekształceń standardowej funkcji prawdopodobieństwa <span class="math inline">\(f(x)\)</span> np. rozkładu normalnego otrzymamy wyniki które będą tożsame z uzyskanymi na podstawie funkcji <span class="math inline">\(g(x\;|\;m,s)\)</span>.</p>
<p><span class="math display" id="eq:RV01" id="eq:Q01" id="eq:I01" id="eq:G01">\[\begin{align}
g(x\,|\,m, s)=\;f\big((x-m)/s\big)/s \quad\longrightarrow\quad
&amp;
\textrm{funkcja gęstości} \tag{2.4}\\[2.5pt]
\int_{-\infty}^{a}g(x\,|\,m,s)\;dx=\;\int_{-\infty}^{a}f\big((x-m)/s\big)\;dx \quad\longrightarrow\quad
&amp;
\textrm{dystrybuanta} \tag{2.5}\\[2.5pt]
q_{\alpha\,|\,m,s}=\;z_{\alpha\,|\,0,1}\cdot s+m \quad\longrightarrow\quad
&amp;
\textrm{kwantyle} \tag{2.6}\\[2.5pt]
rv_{i\,|\,m,s}=\;rv_{i\,|\,0,1}\cdot s+m \quad\longrightarrow\quad
&amp;
\textrm{liczby losowe} \tag{2.7}
\end{align}\]</span></p>
<p>Dla dużych prób rozkłady ciągłe oraz dykretne można przybliżać rozkładem normalnym.
W przypadku rozkładu chi-kwadrat będziemy mieli <span class="math inline">\(N(df,\sqrt{2\;df})\)</span> gdzie <span class="math inline">\(df=n-1\)</span> to stopnie swobody. Natomiast dla rozkładu dwumianowego <span class="math inline">\(N(np,\sqrt{np(1-p)})\)</span>.</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> scipy.stats <span class="im">as</span> stats
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
  
xc <span class="op">=</span> np.arange(<span class="dv">20</span>,<span class="dv">90</span>,<span class="fl">0.01</span>)<span class="op">;</span> xd <span class="op">=</span> np.arange(<span class="dv">5</span>,<span class="dv">25</span><span class="op">+</span><span class="dv">1</span>,<span class="dv">1</span>)

fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">6</span>))
ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)
ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)

ax1.plot(xc,stats.chi2.pdf(xc,df<span class="op">=</span><span class="dv">50</span>))
ax1.plot(xc,stats.norm.pdf(xc,loc<span class="op">=</span><span class="dv">50</span>,scale<span class="op">=</span>(<span class="dv">2</span><span class="op">*</span><span class="dv">50</span>)<span class="op">**</span><span class="fl">0.5</span>))
ax2.vlines(xd, [<span class="dv">0</span>], stats.binom.pmf(xd, n<span class="op">=</span> <span class="dv">50</span>, p<span class="op">=</span> <span class="fl">0.3</span>),lw<span class="op">=</span><span class="dv">2</span>,color<span class="op">=</span><span class="st">&#39;C0&#39;</span>)
ax2.plot(xd,stats.norm.pdf(xd,loc<span class="op">=</span><span class="dv">50</span><span class="op">*</span><span class="fl">0.3</span>,scale<span class="op">=</span>(<span class="dv">50</span><span class="op">*</span><span class="fl">0.3</span><span class="op">*</span><span class="fl">0.7</span>)<span class="op">**</span><span class="fl">0.5</span>),color<span class="op">=</span><span class="st">&#39;C1&#39;</span>)
ax1.set_title(<span class="st">&quot;Przybliżanie rozkładu chi-kwadrat&quot;</span>)
ax2.set_title(<span class="st">&quot;Przybliżanie rozkładu dwumianowego&quot;</span>)
fig.tight_layout()
plt.savefig(<span class="st">&#39;plt01.png&#39;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:plt01"></span>
<img src="plt01.png" alt="Przybliżanie rozkładów." width="100%" />
<p class="caption">
Rysunek 2.1: Przybliżanie rozkładów.
</p>
</div>
</div>
<div id="R22" class="section level2">
<h2><span class="header-section-number">2.2</span> Liniowy model regresji</h2>
<p>Współczynniki modelu liniowego <span class="math inline">\(Y=\hat{\beta} X+\epsilon\)</span> można znaleźć w stosunkowo prosty sposób wykonując działania na macierzach:
<span class="math display" id="eq:n04">\[\begin{equation}
\hat{\beta}=(X^{T}X)^{-1}X^{T}Y
\tag{2.8}
\end{equation}\]</span>
gdzie <span class="math inline">\(Y\)</span> to wektor zmiennej zależnej pochodzącej z rozkładu normalnego natomiast <span class="math inline">\(X\)</span> to macierz zmiennych niezależnych.</p>
<p>Błędy standardowe oszacowanych parametrów to pierwiastki kwadratowe elementów na głównej przekątnej macierzy wariancji i kowariancji:
<span class="math display" id="eq:n05">\[\begin{equation}
D^2(\hat{\beta})=(X^TX)^{-1}S^2_{e}
\tag{2.9}
\end{equation}\]</span>
gdzie <span class="math inline">\(S^2_e=e^Te/(n-k-1)\)</span> to wariancja reszt i <span class="math inline">\(e=Y-\hat{\beta}X\)</span> to wektor reszt.</p>
<p>Stopień wyjaśnienia przez model zmiennej zależnej można ocenić za pomocą współczynnika determinacji:
<span class="math display" id="eq:det">\[\begin{equation}
R^2=\frac{\sum_{i=1}^{n}(\hat{y}-\bar{y})^2}{\sum_{i=1}^{n}(y-\bar{y})^2}
\tag{2.10}
\end{equation}\]</span></p>
<p>Siłę związku dwóch zmiennych można ocenić na podstawie współczynnika korelacji liniowej Pearsona który może być równy pierwiastkowi kwadratowemu współczynnika determinacji ponieważ <span class="math inline">\(|r|=R\)</span>.
<span class="math display" id="eq:cor">\[\begin{equation}
r=\mathrm{cov}(X,Y)/S_XS_Y
\tag{2.11}
\end{equation}\]</span>
gdzie: <span class="math inline">\(\mathrm{cov}(X,Y)\)</span> to kowariancja dwóch zmiennych natomiast <span class="math inline">\(S_X\)</span> i <span class="math inline">\(S_Y\)</span> to odchylenia standardowe zmiennych.</p>
<p>Błąd standardowy korelacji Pearsona dla dużej próby wyznaczamy według wzoru:
<span class="math display" id="eq:SEcor">\[\begin{equation}
SE_{r}=\sqrt{(1-r^2)/n}
\tag{2.12}
\end{equation}\]</span></p>
<p>Wszystkie wyniki można uzyskać za pomocą funkcji <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html#scipy.stats.linregress"><code>scipy.stats.linregress</code></a> ale tylko dla jednej zmiennej objaśniającej.</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy <span class="im">import</span> stats
<span class="im">import</span> numpy <span class="im">as</span> np

x <span class="op">=</span> np.sort(stats.norm.rvs(size<span class="op">=</span><span class="dv">300</span>,loc<span class="op">=</span><span class="dv">3</span>,random_state<span class="op">=</span><span class="dv">2305</span>))
y <span class="op">=</span> np.sort(stats.norm.rvs(size<span class="op">=</span><span class="dv">300</span>,scale<span class="op">=</span><span class="dv">3</span>,random_state<span class="op">=</span><span class="dv">4101</span>))

beta, const, r_value, p_value, SE_beta <span class="op">=</span> stats.linregress(x, y)
SE_r <span class="op">=</span> ((<span class="dv">1</span><span class="op">-</span>r_value<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="bu">len</span>(x)))<span class="op">**</span><span class="fl">0.5</span>
<span class="bu">print</span>(<span class="st">&quot;beta: </span><span class="sc">%f</span><span class="st">, SE_beta: </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> (beta,SE_beta))
<span class="bu">print</span>(<span class="st">&quot;cor: </span><span class="sc">%f</span><span class="st">, SE_cor: </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> (r_value,SE_r))</code></pre>
<pre><code>## beta: 2.820229, SE_beta: 0.009932
## cor: 0.998157, SE_cor: 0.003503</code></pre>
<p>Przedstawiona powyżej procedura szacowania parametrów to metoda najmniejszych kwadratów która minimalizuje sumę kwadratów reszt:
<span class="math display" id="eq:n06">\[\begin{equation}
RSS=e^Te\quad\longrightarrow\quad\mbox{min}
\tag{2.13}
\end{equation}\]</span>
Innym kryterium optymalizacji możne być maksymalizacja logarytmu wiarygodności:
<span class="math display" id="eq:n07">\[\begin{equation}
LL=-\frac{n}{2}\ln(2\pi\sigma^2)-\frac{e^Te}{2\sigma^2}\quad\longrightarrow\quad\mbox{max}
\tag{2.14}
\end{equation}\]</span>
Obie procedury: metoda najmniejszych kwadratów <a href="R2.html#eq:n06">(2.13)</a> i metoda największej wiarygodności <a href="R2.html#eq:n07">(2.14)</a> dla dowolnej liczby zmiennych objaśniających zostały udostępnione w pakiecie <a href="https://www.statsmodels.org/stable/examples/index.html#regression"><code>statsmodels</code></a>.
Ciekawą alternatywą jest wykorzystanie algorytmów optymalizacyjnych ogólnego przeznaczenia z pakietu <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize"><code>scipy.optimize.minimize</code></a>. Takie rozwiązanie (patrz podrozdział <a href="R3.html#R33">3.3</a>) umożliwia szacowanie parametrów modeli o dowolnej postaci analitycznej po uprzednim zdefiniowaniu funkcji logarytmu wiarygodności.</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy <span class="im">import</span> stats
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd

df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>{<span class="st">&#39;x&#39;</span>:np.sort(stats.norm.rvs(size<span class="op">=</span><span class="dv">300</span>,loc<span class="op">=</span><span class="dv">3</span>,random_state<span class="op">=</span><span class="dv">2305</span>)),
                        <span class="st">&#39;y&#39;</span>:np.sort(stats.norm.rvs(size<span class="op">=</span><span class="dv">300</span>,scale<span class="op">=</span><span class="dv">3</span>,random_state<span class="op">=</span><span class="dv">4101</span>))})

<span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf

m <span class="op">=</span> smf.ols(<span class="st">&quot;y~x&quot;</span>, data<span class="op">=</span>df).fit()
<span class="bu">print</span>(m.summary())</code></pre>
<pre><code>##                             OLS Regression Results                            
## ==============================================================================
## Dep. Variable:                      y   R-squared:                       0.996
## Model:                            OLS   Adj. R-squared:                  0.996
## Method:                 Least Squares   F-statistic:                 8.064e+04
## Date:                Mon, 19 Aug 2019   Prob (F-statistic):               0.00
## Time:                        19:16:44   Log-Likelihood:                 99.901
## No. Observations:                 300   AIC:                            -195.8
## Df Residuals:                     298   BIC:                            -188.4
## Df Model:                           1                                         
## Covariance Type:            nonrobust                                         
## ==============================================================================
##                  coef    std err          t      P&gt;|t|      [0.025      0.975]
## ------------------------------------------------------------------------------
## Intercept     -8.2571      0.032   -260.743      0.000      -8.319      -8.195
## x              2.8202      0.010    283.964      0.000       2.801       2.840
## ==============================================================================
## Omnibus:                       29.693   Durbin-Watson:                   0.280
## Prob(Omnibus):                  0.000   Jarque-Bera (JB):              127.091
## Skew:                           0.201   Prob(JB):                     2.53e-28
## Kurtosis:                       6.163   Cond. No.                         10.9
## ==============================================================================
## 
## Warnings:
## [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
<div id="R23" class="section level2">
<h2><span class="header-section-number">2.3</span> Nieliniowy model regresji</h2>
<p>Jeśli badana zależność ma charakter nieliniowy a zmienna objaśniana pochodzi z rozkładu normalnego to można zastosować nieliniową metodę najmniejszych kwadratów np. algorytm Levenberga-Marquardta lub Trust Region Reflective jeśli chcemy dodać ograniczenia przedziałowe na parametry. Obie procedury zostały zaimplementowane do funkcji
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html"><code>scipy.optimize.curve_fit</code></a>. Dodajmy jeszcze, że są to procedury iteracyjne które wymagają określenia parametrów startowych. W pewnych sytuacjach można je wyznaczyć za pomocą tzw. linearyzacji czyli po sprowadzeniu modelu nieliniowego do postaci liniowej ale nie zawsze jest to możliwe. Poniżej przykłady linearyzacji wybranych modeli nieliniowych:</p>
<ul>
<li>model potęgowy:</li>
</ul>
<p><span class="math display" id="eq:n08">\[\begin{equation}
y=a\cdot x^b \quad \longrightarrow \quad \ln(y)=\alpha+\beta\cdot \ln(x)\quad \longrightarrow \quad \exp(\alpha)= a,\quad \beta=b
\tag{2.15}
\end{equation}\]</span></p>
<ul>
<li>model Tornquista 1:</li>
</ul>
<p><span class="math display" id="eq:n09">\[\begin{equation}
y=\frac{ax}{x+b} \quad \longrightarrow \quad \frac{1}{y}=\alpha+\beta\cdot \frac{1}{x}\quad \longrightarrow \quad \frac{1}{\alpha}= a,\quad \frac{\beta}{\alpha}=b
\tag{2.16}
\end{equation}\]</span></p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> scipy.stats <span class="im">as</span> stats
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">from</span> scipy.optimize <span class="im">import</span> curve_fit

x <span class="op">=</span> stats.uniform.rvs(<span class="dv">1</span>,<span class="dv">10</span>,size<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">2305</span>)
mu <span class="op">=</span> <span class="fl">20.8</span> <span class="op">*</span> x<span class="op">**</span><span class="fl">0.45</span>
y <span class="op">=</span> stats.norm.rvs(loc<span class="op">=</span>mu,scale<span class="op">=</span><span class="dv">1</span>,size<span class="op">=</span><span class="dv">100</span>,random_state<span class="op">=</span><span class="dv">2305</span>)
lx <span class="op">=</span> np.log(x)
ly <span class="op">=</span> np.log(y)
df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;x&#39;</span>:x,<span class="st">&#39;y&#39;</span>:y,<span class="st">&#39;lx&#39;</span>:lx,<span class="st">&#39;ly&#39;</span>:ly})

modLog <span class="op">=</span> smf.glm(<span class="st">&#39;ly~lx&#39;</span>, data<span class="op">=</span>df).fit()
p <span class="op">=</span> modLog.params.values
pse <span class="op">=</span> np.diag(modLog.cov_params())<span class="op">**</span><span class="fl">0.5</span>

<span class="kw">def</span> modNLS(x,a,b):
    <span class="cf">return</span> a<span class="op">*</span>x<span class="op">**</span>b

sol, pcov <span class="op">=</span> curve_fit(modNLS, x, y, p0<span class="op">=</span>(np.exp(p[<span class="dv">0</span>]),p[<span class="dv">1</span>]))
se <span class="op">=</span> np.diag(pcov)<span class="op">**</span><span class="fl">0.5</span>

fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">6</span>))
ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)
ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)
lX <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(lx),np.<span class="bu">max</span>(lx), <span class="dv">500</span>)
ax1.plot(lX,p[<span class="dv">0</span>]<span class="op">+</span>p[<span class="dv">1</span>]<span class="op">*</span>lX,
         label<span class="op">=</span><span class="st">&#39;$</span><span class="ch">\\</span><span class="st">alpha$ = </span><span class="sc">%.2f</span><span class="st"> (se: </span><span class="sc">%.4f</span><span class="st">), $</span><span class="ch">\\</span><span class="st">beta$ = </span><span class="sc">%.2f</span><span class="st"> (se: </span><span class="sc">%.4f</span><span class="st">)&#39;</span> <span class="op">%</span> (p[<span class="dv">0</span>],pse[<span class="dv">0</span>],p[<span class="dv">1</span>],pse[<span class="dv">1</span>]))
ax1.plot(lx,ly,<span class="st">&#39;o&#39;</span>,alpha<span class="op">=</span><span class="fl">0.5</span>,label<span class="op">=</span><span class="st">&#39;log dane&#39;</span>)
ax1.set_xlabel(<span class="st">&quot;log x&quot;</span>)
ax1.set_ylabel(<span class="st">&quot;log y&quot;</span>)
ax1.legend()
ax1.set_title(<span class="st">&quot;Liniowa metoda najmniejszych kwadratów\n$</span><span class="ch">\\</span><span class="st">ln(y)=</span><span class="ch">\\</span><span class="st">alpha+</span><span class="ch">\\</span><span class="st">beta</span><span class="ch">\\</span><span class="st">ln(x)$&quot;</span>)
X <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(x),np.<span class="bu">max</span>(x), <span class="dv">500</span>)
ax2.plot(X,modNLS(X,sol[<span class="dv">0</span>],sol[<span class="dv">1</span>]),
         label<span class="op">=</span><span class="st">&#39;a = </span><span class="sc">%.2f</span><span class="st"> (se: </span><span class="sc">%.4f</span><span class="st">), b= </span><span class="sc">%.2f</span><span class="st"> (se: </span><span class="sc">%.4f</span><span class="st">)&#39;</span> <span class="op">%</span> (sol[<span class="dv">0</span>],se[<span class="dv">0</span>],sol[<span class="dv">1</span>],se[<span class="dv">1</span>]))
ax2.plot(x,y,<span class="st">&#39;o&#39;</span>,alpha<span class="op">=</span><span class="fl">0.5</span>,label<span class="op">=</span><span class="st">&#39;dane&#39;</span>)
ax2.set_title(<span class="st">&quot;Nieliniowa metoda najmniejszych kwadratów\n$y=ax^b$&quot;</span>)
ax2.set_xlabel(<span class="st">&quot;x&quot;</span>)
ax2.set_ylabel(<span class="st">&quot;y&quot;</span>)
ax2.legend()
fig.tight_layout()
plt.savefig(<span class="st">&#39;modlin01.png&#39;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:modlin01"></span>
<img src="modlin01.png" alt="Graficzna prezentacja linearyzacji funkcji nieliniowej." width="100%" />
<p class="caption">
Rysunek 2.2: Graficzna prezentacja linearyzacji funkcji nieliniowej.
</p>
</div>
<p>Alternatywnym rozwiązaniem jest metoda największej wiarygodności w której można założyć dowolny rozkład prawdopodobieństwa dla zmiennej zależnej. Ta metoda jest stosowana do estymacji parametrów uogólnionych modeli liniowych w których trzeba określić rozkład z rodziny rozkładów wykładniczych dla zmiennej objaśnianej. Dodatkowo dzięki funkcji wiążącej można rozpatrywać szególne przypadki powiązania zmiennej objaśniającej z predyktorem. Przykładowo dla rozkładu normalnego domyślnie jest estymowany model liniowy - opcja <code>identity</code>: <span class="math inline">\(\hat{\mu}=\hat{y}\)</span> ale możliwe są też takie przypadki jak <code>inverse_power</code>: <span class="math inline">\(\hat{\mu}=1/\hat{y}\)</span> oraz <code>log</code>: <span class="math inline">\(\hat{\mu}=\exp(\hat{y})\)</span> gdzie <span class="math inline">\(\hat{y}=\beta_0+\sum_{j=1}^{n}\beta_j x_{ij}\)</span>. Warto zaznaczyć, że
średnia na skali logarytmicznej nie jest równa logarytmowi średniej na oryginalnej skali tzn.
<span class="math inline">\(E(\ln Y_i)\neq \ln E(Y_i)\)</span>.</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> scipy.stats <span class="im">as</span> stats
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
<span class="im">import</span> statsmodels.api <span class="im">as</span> sm
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">from</span> scipy.optimize <span class="im">import</span> curve_fit

x <span class="op">=</span> stats.uniform.rvs(<span class="dv">1</span>,<span class="dv">7</span>,size<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">2305</span>)
mu <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(<span class="fl">1.25+8.25</span><span class="op">*</span>x)
MU <span class="op">=</span> np.exp(<span class="fl">3.25+0.88</span><span class="op">*</span>x)
y <span class="op">=</span> stats.norm.rvs(loc<span class="op">=</span>mu,scale<span class="op">=</span><span class="fl">0.0025</span>,size<span class="op">=</span><span class="dv">100</span>,random_state<span class="op">=</span><span class="dv">2305</span>)
z <span class="op">=</span> MU<span class="op">+</span>stats.norm.rvs(scale<span class="op">=</span><span class="dv">200</span>,size<span class="op">=</span><span class="dv">100</span>,random_state<span class="op">=</span><span class="dv">2305</span>)
X <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(x),np.<span class="bu">max</span>(x), <span class="dv">500</span>)
  
gaus1 <span class="op">=</span> smf.glm(<span class="st">&#39;y~x&#39;</span>, data<span class="op">=</span>pd.DataFrame({<span class="st">&#39;x&#39;</span>:x,<span class="st">&#39;y&#39;</span>:y}),<span class="op">\</span>
        family<span class="op">=</span>sm.families.Gaussian(sm.families.links.inverse_power)).fit()
p <span class="op">=</span> gaus1.params.values
pSE <span class="op">=</span> np.diag(gaus1.cov_params())<span class="op">**</span><span class="fl">0.5</span>
gaus2 <span class="op">=</span> smf.glm(<span class="st">&#39;z~x&#39;</span>, data<span class="op">=</span>pd.DataFrame({<span class="st">&#39;x&#39;</span>:x,<span class="st">&#39;z&#39;</span>:z}),<span class="op">\</span>
        family<span class="op">=</span>sm.families.Gaussian(sm.families.links.log)).fit()
P <span class="op">=</span> gaus2.params.values
Pse <span class="op">=</span> np.diag(gaus2.cov_params())<span class="op">**</span><span class="fl">0.5</span>
<span class="bu">print</span>(<span class="st">&quot;GLM: family=Gaussian, link=&#39;inverse_power&#39;&quot;</span>)
<span class="bu">print</span>(gaus1.summary().tables[<span class="dv">1</span>])
<span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">GLM: family=Gaussian, link=&#39;log&#39;&quot;</span>)
<span class="bu">print</span>(gaus2.summary().tables[<span class="dv">1</span>])

fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">6</span>))
ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)
ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)
ax1.plot(X, <span class="dv">1</span><span class="op">/</span>(p[<span class="dv">0</span>]<span class="op">+</span>p[<span class="dv">1</span>]<span class="op">*</span>X),label<span class="op">=</span><span class="st">&#39;a = </span><span class="sc">%.4f</span><span class="st">, b= </span><span class="sc">%.4f</span><span class="st">&#39;</span> <span class="op">%</span> (p[<span class="dv">0</span>],p[<span class="dv">1</span>]))
ax1.plot(x,y,<span class="st">&#39;o&#39;</span>,alpha<span class="op">=</span><span class="fl">0.5</span>,label<span class="op">=</span><span class="st">&quot;y&quot;</span>)         
ax1.set_title(<span class="st">&quot;GLM: family=Gaussian, link=&#39;inverse_power&#39;</span><span class="ch">\n</span><span class="st"> $</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">mu}=</span><span class="ch">\\</span><span class="st">frac</span><span class="sc">{1}</span><span class="st">{a+bx}$&quot;</span>)
ax1.legend()
ax2.plot(X, np.exp(P[<span class="dv">0</span>]<span class="op">+</span>P[<span class="dv">1</span>]<span class="op">*</span>X),label<span class="op">=</span><span class="st">&#39;a = </span><span class="sc">%.4f</span><span class="st">, b= </span><span class="sc">%.4f</span><span class="st">&#39;</span> <span class="op">%</span> (P[<span class="dv">0</span>],P[<span class="dv">1</span>]))
ax2.plot(x,z,<span class="st">&#39;o&#39;</span>,alpha<span class="op">=</span><span class="fl">0.5</span>,label<span class="op">=</span><span class="st">&#39;z&#39;</span>)
ax2.set_title(<span class="st">&quot;GLM: family=Gaussian, link=&#39;log&#39;</span><span class="ch">\n</span><span class="st"> $</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">mu}=</span><span class="ch">\\</span><span class="st">exp(a+bx)$&quot;</span>)
ax2.legend()
fig.tight_layout()
plt.savefig(<span class="st">&#39;modlin02.png&#39;</span>)</code></pre>
<pre><code>## GLM: family=Gaussian, link=&#39;inverse_power&#39;
## ==============================================================================
##                  coef    std err          z      P&gt;|z|      [0.025      0.975]
## ------------------------------------------------------------------------------
## Intercept      1.1263      0.214      5.275      0.000       0.708       1.545
## x              8.2971      0.127     65.083      0.000       8.047       8.547
## ==============================================================================
## 
## GLM: family=Gaussian, link=&#39;log&#39;
## ==============================================================================
##                  coef    std err          z      P&gt;|z|      [0.025      0.975]
## ------------------------------------------------------------------------------
## Intercept      3.2250      0.030    106.185      0.000       3.165       3.285
## x              0.8834      0.004    216.194      0.000       0.875       0.891
## ==============================================================================</code></pre>
<div class="figure" style="text-align: center"><span id="fig:modlin02"></span>
<img src="modlin02.png" alt="Graficzna prezentacja dwóch funkcji wiążących z wykorzystaniem rozkładu Gaussa." width="100%" />
<p class="caption">
Rysunek 2.3: Graficzna prezentacja dwóch funkcji wiążących z wykorzystaniem rozkładu Gaussa.
</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="R3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["PythonStat.pdf", "PythonStat.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
